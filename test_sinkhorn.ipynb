{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ot as pot\n",
    "import torch\n",
    "import torchdyn\n",
    "from torchdyn.core import NeuralODE\n",
    "from torchdyn.datasets import generate_moons\n",
    "\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "from torchcfm.models.models import *\n",
    "from torchcfm.utils import *\n",
    "\n",
    "savedir = \"models/8gaussian-moons_sinkhorn\"\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[KeOps] error: cuMemAlloc(&p_data, sizeof(TYPE *) * nargs) failed with error CUDA_ERROR_OUT_OF_MEMORY\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[KeOps] Cuda error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m x0 \u001b[39m=\u001b[39m sample_8gaussians(batch_size)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m x1 \u001b[39m=\u001b[39m sample_moons(batch_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 19\u001b[0m t_train, xt, ut \u001b[39m=\u001b[39m FM\u001b[39m.\u001b[39;49msample_location_and_conditional_flow(x0, x1, t)\n\u001b[1;32m     20\u001b[0m FM\u001b[39m.\u001b[39mclear_all()\n\u001b[1;32m     22\u001b[0m vt \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39mcat([xt\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m), t_train[:, \u001b[39mNone\u001b[39;00m]\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/conditional-flow-matching/torchcfm/conditional_flow_matching.py:458\u001b[0m, in \u001b[0;36mSinkhornFlowMatcher.sample_location_and_conditional_flow\u001b[0;34m(self, x0, x1, t)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_location_and_conditional_flow\u001b[39m(\u001b[39mself\u001b[39m, x0, x1, t):\n\u001b[1;32m    457\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSD\u001b[39m.\u001b[39mset_bs_t_particles(batch_size\u001b[39m=\u001b[39mx0\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], T\u001b[39m=\u001b[39mt, particles\u001b[39m=\u001b[39mx0)\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSD\u001b[39m.\u001b[39;49msample_trajectory(x1)\n\u001b[1;32m    459\u001b[0m     vector_field, x_traj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSD\u001b[39m.\u001b[39msample_state()\n\u001b[1;32m    460\u001b[0m     t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, t, (x0\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],))\u001b[39m.\u001b[39mtype_as(x0)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/conditional-flow-matching/torchcfm/optimal_transport.py:159\u001b[0m, in \u001b[0;36msample_trajectory\u001b[0;34m(self, x1)\u001b[0m\n\u001b[1;32m    153\u001b[0m     self.init_mass = torch.ones(batch_size, device = self.device) / batch_size\n\u001b[1;32m    156\u001b[0m def sample_trajectory(self, x1):\n\u001b[1;32m    157\u001b[0m     for step in range(self.T):\n\u001b[1;32m    158\u001b[0m         # use Index sd_lr * exp((t - T) / (T / 4))  \n\u001b[0;32m--> 159\u001b[0m         # lr = self.opts.SD_lr * math.exp((step - self.opts.T) / (self.opts.T / 4))\n\u001b[1;32m    160\u001b[0m         lr = self.SD_lr\n\u001b[1;32m    161\u001b[0m         self.algorithm.one_step_update(\n\u001b[1;32m    162\u001b[0m             step_size = lr,\n\u001b[1;32m    163\u001b[0m             init_particles = self.support,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m             tgt_mass = self.tgt_mass\n\u001b[1;32m    167\u001b[0m         )\n",
      "File \u001b[0;32m~/conditional-flow-matching/torchcfm/Sinkhorn_decent.py:24\u001b[0m, in \u001b[0;36mSD.one_step_update\u001b[0;34m(self, init_particles, init_mass, step_size, tgt_support, tgt_mass, **kw)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparticles\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m first_var_ab, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpotential_op(\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmass, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparticles, tgt_mass\u001b[39m.\u001b[39mcontiguous(), tgt_support\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m first_var_aa, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpotential_op(\n\u001b[1;32m     25\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmass, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparticles, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmass, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparticles \n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m first_var_ab_grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(\n\u001b[1;32m     28\u001b[0m     torch\u001b[39m.\u001b[39msum(first_var_ab), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparticles\n\u001b[1;32m     29\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m first_var_aa_grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(\n\u001b[1;32m     31\u001b[0m     torch\u001b[39m.\u001b[39msum(first_var_aa), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparticles\n\u001b[1;32m     32\u001b[0m )[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/geomloss/samples_loss.py:265\u001b[0m, in \u001b[0;36mSamplesLoss.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     α, x, β, y \u001b[39m=\u001b[39m α\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), β\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), y\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    264\u001b[0m \u001b[39m# Run --------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m values \u001b[39m=\u001b[39m routines[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss][backend](\n\u001b[1;32m    266\u001b[0m     α,\n\u001b[1;32m    267\u001b[0m     x,\n\u001b[1;32m    268\u001b[0m     β,\n\u001b[1;32m    269\u001b[0m     y,\n\u001b[1;32m    270\u001b[0m     p\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp,\n\u001b[1;32m    271\u001b[0m     blur\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblur,\n\u001b[1;32m    272\u001b[0m     reach\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreach,\n\u001b[1;32m    273\u001b[0m     diameter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiameter,\n\u001b[1;32m    274\u001b[0m     scaling\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaling,\n\u001b[1;32m    275\u001b[0m     truncate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtruncate,\n\u001b[1;32m    276\u001b[0m     cost\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcost,\n\u001b[1;32m    277\u001b[0m     kernel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel,\n\u001b[1;32m    278\u001b[0m     cluster_scale\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster_scale,\n\u001b[1;32m    279\u001b[0m     debias\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdebias,\n\u001b[1;32m    280\u001b[0m     potentials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpotentials,\n\u001b[1;32m    281\u001b[0m     labels_x\u001b[39m=\u001b[39;49ml_x,\n\u001b[1;32m    282\u001b[0m     labels_y\u001b[39m=\u001b[39;49ml_y,\n\u001b[1;32m    283\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m \u001b[39m# Make sure that the output has the correct shape ------------------------------------\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    288\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpotentials\n\u001b[1;32m    289\u001b[0m ):  \u001b[39m# Return some dual potentials (= test functions) sampled on the input measures\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/geomloss/sinkhorn_samples.py:401\u001b[0m, in \u001b[0;36msinkhorn_online\u001b[0;34m(a, x, b, y, p, blur, reach, diameter, scaling, cost, debias, potentials, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m C_xy, C_yx \u001b[39m=\u001b[39m ((x, y\u001b[39m.\u001b[39mdetach()), (y, x\u001b[39m.\u001b[39mdetach()))\n\u001b[1;32m    397\u001b[0m diameter, eps, eps_list, rho \u001b[39m=\u001b[39m scaling_parameters(\n\u001b[1;32m    398\u001b[0m     x, y, p, blur, reach, diameter, scaling\n\u001b[1;32m    399\u001b[0m )\n\u001b[0;32m--> 401\u001b[0m f_aa, g_bb, g_ab, f_ba \u001b[39m=\u001b[39m sinkhorn_loop(\n\u001b[1;32m    402\u001b[0m     softmin,\n\u001b[1;32m    403\u001b[0m     log_weights(a),\n\u001b[1;32m    404\u001b[0m     log_weights(b),\n\u001b[1;32m    405\u001b[0m     C_xx,\n\u001b[1;32m    406\u001b[0m     C_yy,\n\u001b[1;32m    407\u001b[0m     C_xy,\n\u001b[1;32m    408\u001b[0m     C_yx,\n\u001b[1;32m    409\u001b[0m     eps_list,\n\u001b[1;32m    410\u001b[0m     rho,\n\u001b[1;32m    411\u001b[0m     debias\u001b[39m=\u001b[39;49mdebias,\n\u001b[1;32m    412\u001b[0m )\n\u001b[1;32m    414\u001b[0m \u001b[39mreturn\u001b[39;00m sinkhorn_cost(\n\u001b[1;32m    415\u001b[0m     eps,\n\u001b[1;32m    416\u001b[0m     rho,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     potentials\u001b[39m=\u001b[39mpotentials,\n\u001b[1;32m    426\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/geomloss/sinkhorn_divergence.py:482\u001b[0m, in \u001b[0;36msinkhorn_loop\u001b[0;34m(softmin, a_logs, b_logs, C_xxs, C_yys, C_xys, C_yxs, eps_list, rho, jumps, kernel_truncation, truncate, cost, extrapolate, debias, last_extrapolation)\u001b[0m\n\u001b[1;32m    472\u001b[0m damping \u001b[39m=\u001b[39m dampening(eps, rho)  \u001b[39m# eps and damping change across iterations\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# Line 7: \"coordinate ascent\" on the dual problems -----------------------------\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# N.B.: As discussed in Section 3.3.3 of Jean Feydy's PhD thesis,\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39m#       we perform \"symmetric\" instead of \"alternate\" updates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39m#       Sinkhorn formulas, and update both dual vectors\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39m#       simultaneously.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m ft_ba \u001b[39m=\u001b[39m damping \u001b[39m*\u001b[39m softmin(eps, C_xy, b_log \u001b[39m+\u001b[39;49m g_ab \u001b[39m/\u001b[39;49m eps)  \u001b[39m# b -> a\u001b[39;00m\n\u001b[1;32m    483\u001b[0m gt_ab \u001b[39m=\u001b[39m damping \u001b[39m*\u001b[39m softmin(eps, C_yx, a_log \u001b[39m+\u001b[39m f_ba \u001b[39m/\u001b[39m eps)  \u001b[39m# a -> b\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39m# See Fig. 3.21 in Jean Feydy's PhD thesis to see the importance\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39m# of debiasing when the target \"blur\" or \"eps**(1/p)\" value is larger\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m# than the average distance between samples x_i, y_j and their neighbours.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/geomloss/sinkhorn_samples.py:345\u001b[0m, in \u001b[0;36msoftmin_online\u001b[0;34m(eps, C_xy, h_y, log_conv)\u001b[0m\n\u001b[1;32m    342\u001b[0m B \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    343\u001b[0m h \u001b[39m=\u001b[39m h_y\u001b[39m.\u001b[39mview(B, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m batch \u001b[39melse\u001b[39;00m h_y\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m out \u001b[39m=\u001b[39m \u001b[39m-\u001b[39meps \u001b[39m*\u001b[39m log_conv(x, y, h, torch\u001b[39m.\u001b[39;49mTensor([\u001b[39m1\u001b[39;49m \u001b[39m/\u001b[39;49m eps])\u001b[39m.\u001b[39;49mtype_as(x))\n\u001b[1;32m    347\u001b[0m \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mview(B, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m batch \u001b[39melse\u001b[39;00m out\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:627\u001b[0m, in \u001b[0;36mGenred.__call__\u001b[0;34m(self, backend, device_id, ranges, out, *args)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[39melif\u001b[39;00m nred \u001b[39m>\u001b[39m \u001b[39m2048\u001b[39m \u001b[39mand\u001b[39;00m dtype \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfloat16\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhalf\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    623\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    624\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msize of input array is too large for Arg type reduction with float16 dtype..\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m         )\n\u001b[0;32m--> 627\u001b[0m out \u001b[39m=\u001b[39m GenredAutograd\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    628\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformula,\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maliases,\n\u001b[1;32m    630\u001b[0m     backend,\n\u001b[1;32m    631\u001b[0m     dtype,\n\u001b[1;32m    632\u001b[0m     device_id,\n\u001b[1;32m    633\u001b[0m     ranges,\n\u001b[1;32m    634\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptional_flags,\n\u001b[1;32m    635\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrec_multVar_highdim,\n\u001b[1;32m    636\u001b[0m     nx,\n\u001b[1;32m    637\u001b[0m     ny,\n\u001b[1;32m    638\u001b[0m     out,\n\u001b[1;32m    639\u001b[0m     \u001b[39m*\u001b[39;49margs\n\u001b[1;32m    640\u001b[0m )\n\u001b[1;32m    642\u001b[0m \u001b[39mreturn\u001b[39;00m postprocess(out, \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction_op, nout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_arg, dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:117\u001b[0m, in \u001b[0;36mGenredAutograd.forward\u001b[0;34m(ctx, formula, aliases, backend, dtype, device_id_request, ranges, optional_flags, rec_multVar_highdim, nx, ny, out, *args)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m ranges:\n\u001b[1;32m    115\u001b[0m     ranges \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(r\u001b[39m.\u001b[39mcontiguous() \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m ranges)\n\u001b[0;32m--> 117\u001b[0m result \u001b[39m=\u001b[39m myconv\u001b[39m.\u001b[39;49mgenred_pytorch(\n\u001b[1;32m    118\u001b[0m     device_args, ranges, nx, ny, nbatchdims, out, \u001b[39m*\u001b[39;49margs\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    121\u001b[0m \u001b[39m# relying on the 'ctx.saved_variables' attribute is necessary  if you want to be able to differentiate the output\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m#  of the backward once again. It helps pytorch to keep track of 'who is who'.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m ctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39m*\u001b[39margs, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/pykeops/common/keops_io/LoadKeOps.py:232\u001b[0m, in \u001b[0;36mLoadKeOps.genred\u001b[0;34m(self, device_args, ranges, nx, ny, nbatchdims, out, *args)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_ptr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtools\u001b[39m.\u001b[39mget_pointer(out)\n\u001b[1;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutshape \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 232\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_keops(nx, ny)\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfloat16\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    235\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpykeops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhalf2_convert\u001b[39;00m \u001b[39mimport\u001b[39;00m postprocess_half2\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/pykeops/common/keops_io/LoadKeOps_nvrtc.py:42\u001b[0m, in \u001b[0;36mLoadKeOps_nvrtc_class.call_keops\u001b[0;34m(self, nx, ny)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_keops\u001b[39m(\u001b[39mself\u001b[39m, nx, ny):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlaunch_keops(\n\u001b[1;32m     43\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mtagHostDevice,\n\u001b[1;32m     44\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mdimy,\n\u001b[1;32m     45\u001b[0m         nx,\n\u001b[1;32m     46\u001b[0m         ny,\n\u001b[1;32m     47\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mtagI,\n\u001b[1;32m     48\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mtagZero,\n\u001b[1;32m     49\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49muse_half,\n\u001b[1;32m     50\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mtag1D2D,\n\u001b[1;32m     51\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mdimred,\n\u001b[1;32m     52\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mcuda_block_size,\n\u001b[1;32m     53\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49muse_chunk_mode,\n\u001b[1;32m     54\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mindsi,\n\u001b[1;32m     55\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mindsj,\n\u001b[1;32m     56\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mindsp,\n\u001b[1;32m     57\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mdim,\n\u001b[1;32m     58\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mdimsx,\n\u001b[1;32m     59\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mdimsy,\n\u001b[1;32m     60\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mdimsp,\n\u001b[1;32m     61\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mranges_ptr_new,\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutshape,\n\u001b[1;32m     63\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_ptr,\n\u001b[1;32m     64\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs_ptr_new,\n\u001b[1;32m     65\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margshapes_new,\n\u001b[1;32m     66\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [KeOps] Cuda error."
     ]
    }
   ],
   "source": [
    "blur = 0.05\n",
    "scaling = 0.95\n",
    "backend = 'online'\n",
    "lr = 0.01\n",
    "device = 'cuda:0'\n",
    "t = 100\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "model = MLP(dim=dim, time_varying=True)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "FM = SinkhornFlowMatcher(blur = blur, scaling = scaling, backend = backend, lr = lr, device = device)\n",
    "start = time.time()\n",
    "for k in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = sample_8gaussians(batch_size).to(device)\n",
    "    x1 = sample_moons(batch_size).to(device)\n",
    "\n",
    "    t_train, xt, ut = FM.sample_location_and_conditional_flow(x0, x1, t)\n",
    "    FM.clear_all()\n",
    "\n",
    "    vt = model(torch.cat([xt.to('cpu'), t_train[:, None].to('cpu')], dim=-1))\n",
    "    loss = torch.mean((vt - ut.to('cpu')) ** 2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (k + 1) % 5000 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "        node = NeuralODE(\n",
    "            torch_wrapper(model), solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            traj = node.trajectory(\n",
    "                sample_8gaussians(1024),\n",
    "                t_span=torch.linspace(0, 1, 100),\n",
    "            )\n",
    "            plot_trajectories(traj)\n",
    "        break\n",
    "torch.save(model, f\"{savedir}/cfm_v1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
